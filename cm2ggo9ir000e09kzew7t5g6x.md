---
title: "Exploiting LLM APIs with excessive agency"
seoTitle: "Exploiting LLM APIs: Mapping LLM API attack surface"
seoDescription: "Learn to exploit Large Language Model APIs vulnerabilities, detect and hack LLM integrations like SSRF, and secure data from potential attacks"
datePublished: Sat Oct 19 2024 17:57:19 GMT+0000 (Coordinated Universal Time)
cuid: cm2ggo9ir000e09kzew7t5g6x
slug: exploiting-llm-apis-with-excessive-agency
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1729360882925/a0e854b8-b5dd-4c77-a95e-09f9e1bbf6d9.png
tags: hacking, web-security, llm, chatgpt, sqli

---

### Introduction

Organizations are quickly integrating Large Language Models (LLMs) to enhance their online customer experience. However, this exposes them to web LLM attacks, which exploit the model's access to data, APIs, or user information that an attacker cannot directly access.

In general, attacking an LLM integration is like exploiting a [server-side request forgery (SSRF) vulnerability](https://portswigger.net/web-security/ssrf). In both situations, an attacker uses a server-side system to attack another part that can't be accessed directly.

### **Detecting LLM vulnerabilities**

Our recommended method for detecting LLM vulnerabilities is:

1. Identify the LLM's inputs, including both direct inputs (like a prompt) and indirect inputs (such as training data).
    
2. Determine what data and APIs the LLM can access.
    
3. Examine this new attack surface for vulnerabilities.
    

### **Mapping LLM API attack surface**

#### Tasks

* To solve the lab, use the LLM to delete the user `carlos`.
    

#### **Required Knowledge**

To solve this lab, you need to know:

* How LLM APIs function.
    
* How to map the LLM API attack surface.
    

#### Steps

1. Access the web and get live chat.
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1729359814469/733ce0e9-8ea5-45c5-bffd-60440e691a9b.png align="left")
    
2. Ask normal prompt in chatbox. Lol :)
    
3. ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1729359768814/cc1cab89-889f-4166-add5-d9cc0dfd43f6.png align="center")
    
    Try to ask `what APIs it has access to`
    
4. ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1729359976588/52766f34-f72b-4257-a082-dadc114aad15.png align="center")
    
    We got idea about LLM is using SQL database. Try to inject SQLI payload now.
    
    Try to inject payload.
    

```sql
SELECT * FROM users
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1729360360875/c73bdf16-84fd-4749-b463-db5ac8d83f81.png align="center")

  
5\. We can see `carlos`, `username`. `password` and `email`. Now letâ€™s delete `carlos`.

```sql
DELETE FROM users WHERE username='carlos'
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1729360480536/b1bd8fe2-9a9f-4887-99eb-edb4274ebe16.png align="center")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1729360513352/9afb62bc-3fcd-4624-9bb6-14fbc522922a.png align="center")

#### **Congratulations, you solved the lab!**

#llmhacking #chatbot #hacking #webhacking #happylearning